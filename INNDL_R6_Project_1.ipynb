{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "g9s5xS5C4HJ0",
    "outputId": "7cca41fe-34ad-40b6-da76-e965acf892fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.0-rc2'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "0lnzR7e34tYC",
    "outputId": "084399bb-59d1-40b4-fab6-7de335a991db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
       "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
       "1          2    15647311      Hill  ...               1       112542.58      0\n",
       "2          3    15619304      Onio  ...               0       113931.57      1\n",
       "3          4    15701354      Boni  ...               0        93826.63      0\n",
       "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  \n",
    "#1. Read the dataset\n",
    "df = pd.read_csv(\"bank.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "golOHlF24_NW",
    "outputId": "456bdd51-7421-48f8-ab5f-ce22074c454e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# There are 3 features which ate of object data type which we will be converting to numeric in further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "FFrmmD7m5Ere",
    "outputId": "6f2d1a15-8f66-44c1-d361-e1cf024ac36c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId  ...  EstimatedSalary        Exited\n",
       "count  10000.00000  1.000000e+04  ...     10000.000000  10000.000000\n",
       "mean    5000.50000  1.569094e+07  ...    100090.239881      0.203700\n",
       "std     2886.89568  7.193619e+04  ...     57510.492818      0.402769\n",
       "min        1.00000  1.556570e+07  ...        11.580000      0.000000\n",
       "25%     2500.75000  1.562853e+07  ...     51002.110000      0.000000\n",
       "50%     5000.50000  1.569074e+07  ...    100193.915000      0.000000\n",
       "75%     7500.25000  1.575323e+07  ...    149388.247500      0.000000\n",
       "max    10000.00000  1.581569e+07  ...    199992.480000      1.000000\n",
       "\n",
       "[8 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "# There are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "JwviFrNj5kvG",
    "outputId": "71454a5a-5685-4303-9c64-25957e4fd8d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Exited'].value_counts()\n",
    "\n",
    "# Observing a class imbalance. We have more data points for customers who have not exited than who have exited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hBb4Sqcp5qx3",
    "outputId": "ecf486b3-9fc7-4099-f6d1-7f1c00a2adb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Drop the columns which are unique for all users like IDs (2.5 points)\n",
    "\n",
    "#Dropping columns ID and Rownumber, Surname\n",
    "\n",
    "df = df.drop(columns = ['RowNumber','CustomerId','Surname'], axis = 1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1LtkqjDF6CNQ"
   },
   "outputs": [],
   "source": [
    "# Converting Categorical variable to numeric\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "le= LabelEncoder()\n",
    "df['Gender'] = le.fit_transform(df['Gender'])\n",
    "df['Geography'] = le.fit_transform(df['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "YpJjLwnd6I9Y",
    "outputId": "aeb0b995-cb43-4529-c587-364eb67fe3a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6619</th>\n",
       "      <td>647</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>97041.16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23132.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7860</th>\n",
       "      <td>659</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>95377.13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187551.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>626</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>148610.41</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>104502.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>703</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85547.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9044</th>\n",
       "      <td>560</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128882.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8294</th>\n",
       "      <td>704</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>175509.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152039.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>187800.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6510</th>\n",
       "      <td>619</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>62400.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132498.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>732</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25438.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>704</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>147004.34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64381.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
       "6619          647          0       1  ...               1         23132.73       0\n",
       "7860          659          0       1  ...               1        187551.24       0\n",
       "2900          626          2       0  ...               1        104502.02       1\n",
       "7834          703          0       1  ...               0         85547.33       1\n",
       "9044          560          2       1  ...               0        128882.66       1\n",
       "8294          704          2       0  ...               0        152039.67       0\n",
       "1595          677          0       1  ...               0        187800.63       0\n",
       "6510          619          2       1  ...               1        132498.39       1\n",
       "4698          732          0       1  ...               1         25438.87       0\n",
       "1260          704          1       1  ...               0         64381.33       1\n",
       "\n",
       "[10 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Geography and Gender columns both have converted to numeric. And RowNumber, CustomerId, Surname are dropped from teh dataframe\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6oT_JTU37VbB"
   },
   "outputs": [],
   "source": [
    "#3. Distinguish the feature and target set\n",
    "X = df.drop(columns = 'Exited', axis = 1)\n",
    "Y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "D44srHje7kEm",
    "outputId": "1c479ca1-419f-467e-f467-c974de141e13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>683</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>110829.52</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24938.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>651</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170099.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  ...  IsActiveMember  EstimatedSalary\n",
       "1697          683          0  ...               0         24938.84\n",
       "9729          651          0  ...               1        170099.23\n",
       "\n",
       "[2 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "FNkNQxjs7ocf",
    "outputId": "63010062-61c9-402b-d4e4-e4f328e42963"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9692    0\n",
       "9885    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lozydWKR76-4",
    "outputId": "5421f102-a3de-4bc0-ecb7-86d398c21161"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. Divide the data set into Train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=43, stratify = Y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KA_p8cE29Fcf"
   },
   "outputs": [],
   "source": [
    "#5. Normalize the train and test data (2.5 points)\n",
    "# normalising using standard scalar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train_std = StandardScaler().fit_transform(X_train)\n",
    "X_test_std = StandardScaler().fit_transform(X_test)\n",
    "Y_train = Y_train.to_numpy()\n",
    "Y_test = Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7Li0tuy9WqW"
   },
   "outputs": [],
   "source": [
    "# Converting Y_train and Y_test to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fnpo1Xx19sTn",
    "outputId": "5e705f39-12b9-43e2-eb98-6e8517f32037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                140       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 227\n",
      "Trainable params: 227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7806 - val_loss: 0.5109 - val_accuracy: 0.7965\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.7962 - val_loss: 0.4895 - val_accuracy: 0.7965\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7962 - val_loss: 0.4759 - val_accuracy: 0.7965\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7962 - val_loss: 0.4665 - val_accuracy: 0.7965\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7962 - val_loss: 0.4591 - val_accuracy: 0.7965\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7962 - val_loss: 0.4532 - val_accuracy: 0.7965\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7962 - val_loss: 0.4485 - val_accuracy: 0.7965\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7962 - val_loss: 0.4450 - val_accuracy: 0.7965\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7962 - val_loss: 0.4421 - val_accuracy: 0.7965\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7962 - val_loss: 0.4398 - val_accuracy: 0.7965\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7962 - val_loss: 0.4378 - val_accuracy: 0.7965\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.7960 - val_loss: 0.4363 - val_accuracy: 0.7970\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7964 - val_loss: 0.4348 - val_accuracy: 0.7965\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7965 - val_loss: 0.4334 - val_accuracy: 0.7975\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7985 - val_loss: 0.4322 - val_accuracy: 0.8015\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8015 - val_loss: 0.4309 - val_accuracy: 0.8020\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.8041 - val_loss: 0.4299 - val_accuracy: 0.8070\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.8096 - val_loss: 0.4287 - val_accuracy: 0.8110\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.8100 - val_loss: 0.4276 - val_accuracy: 0.8175\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.8136 - val_loss: 0.4264 - val_accuracy: 0.8195\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8155 - val_loss: 0.4252 - val_accuracy: 0.8210\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.8166 - val_loss: 0.4241 - val_accuracy: 0.8235\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.8196 - val_loss: 0.4228 - val_accuracy: 0.8230\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4259 - accuracy: 0.8184 - val_loss: 0.4216 - val_accuracy: 0.8270\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4249 - accuracy: 0.8200 - val_loss: 0.4204 - val_accuracy: 0.8310\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4240 - accuracy: 0.8213 - val_loss: 0.4190 - val_accuracy: 0.8305\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8229 - val_loss: 0.4178 - val_accuracy: 0.8295\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.8253 - val_loss: 0.4165 - val_accuracy: 0.8300\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.8269 - val_loss: 0.4154 - val_accuracy: 0.8325\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4204 - accuracy: 0.8273 - val_loss: 0.4142 - val_accuracy: 0.8330\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4195 - accuracy: 0.8270 - val_loss: 0.4130 - val_accuracy: 0.8330\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8279 - val_loss: 0.4118 - val_accuracy: 0.8330\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8281 - val_loss: 0.4105 - val_accuracy: 0.8355\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8285 - val_loss: 0.4093 - val_accuracy: 0.8355\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8284 - val_loss: 0.4081 - val_accuracy: 0.8355\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8296 - val_loss: 0.4068 - val_accuracy: 0.8370\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8298 - val_loss: 0.4055 - val_accuracy: 0.8365\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8296 - val_loss: 0.4041 - val_accuracy: 0.8365\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4120 - accuracy: 0.8299 - val_loss: 0.4028 - val_accuracy: 0.8355\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.8294 - val_loss: 0.4013 - val_accuracy: 0.8370\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4096 - accuracy: 0.8320 - val_loss: 0.4003 - val_accuracy: 0.8395\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4087 - accuracy: 0.8314 - val_loss: 0.3987 - val_accuracy: 0.8400\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.8316 - val_loss: 0.3977 - val_accuracy: 0.8435\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4059 - accuracy: 0.8322 - val_loss: 0.3959 - val_accuracy: 0.8400\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8335 - val_loss: 0.3944 - val_accuracy: 0.8420\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4032 - accuracy: 0.8329 - val_loss: 0.3930 - val_accuracy: 0.8430\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8324 - val_loss: 0.3917 - val_accuracy: 0.8415\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3999 - accuracy: 0.8325 - val_loss: 0.3905 - val_accuracy: 0.8410\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3986 - accuracy: 0.8342 - val_loss: 0.3892 - val_accuracy: 0.8450\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3972 - accuracy: 0.8332 - val_loss: 0.3880 - val_accuracy: 0.8465\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8344 - val_loss: 0.3865 - val_accuracy: 0.8445\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3942 - accuracy: 0.8345 - val_loss: 0.3852 - val_accuracy: 0.8470\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8357 - val_loss: 0.3840 - val_accuracy: 0.8475\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.8350 - val_loss: 0.3827 - val_accuracy: 0.8470\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8361 - val_loss: 0.3816 - val_accuracy: 0.8460\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3882 - accuracy: 0.8364 - val_loss: 0.3800 - val_accuracy: 0.8470\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8355 - val_loss: 0.3788 - val_accuracy: 0.8475\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3849 - accuracy: 0.8369 - val_loss: 0.3776 - val_accuracy: 0.8470\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8369 - val_loss: 0.3759 - val_accuracy: 0.8480\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8379 - val_loss: 0.3752 - val_accuracy: 0.8500\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3807 - accuracy: 0.8385 - val_loss: 0.3748 - val_accuracy: 0.8495\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3796 - accuracy: 0.8386 - val_loss: 0.3743 - val_accuracy: 0.8495\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8389 - val_loss: 0.3713 - val_accuracy: 0.8515\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3770 - accuracy: 0.8384 - val_loss: 0.3707 - val_accuracy: 0.8500\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8404 - val_loss: 0.3695 - val_accuracy: 0.8520\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3747 - accuracy: 0.8416 - val_loss: 0.3680 - val_accuracy: 0.8530\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8422 - val_loss: 0.3662 - val_accuracy: 0.8565\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8424 - val_loss: 0.3654 - val_accuracy: 0.8560\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8435 - val_loss: 0.3647 - val_accuracy: 0.8590\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8432 - val_loss: 0.3632 - val_accuracy: 0.8590\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8449 - val_loss: 0.3621 - val_accuracy: 0.8585\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8460 - val_loss: 0.3619 - val_accuracy: 0.8600\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8471 - val_loss: 0.3602 - val_accuracy: 0.8585\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3673 - accuracy: 0.8470 - val_loss: 0.3585 - val_accuracy: 0.8595\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3668 - accuracy: 0.8475 - val_loss: 0.3580 - val_accuracy: 0.8620\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3661 - accuracy: 0.8481 - val_loss: 0.3574 - val_accuracy: 0.8605\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8469 - val_loss: 0.3560 - val_accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8485 - val_loss: 0.3561 - val_accuracy: 0.8625\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8516 - val_loss: 0.3552 - val_accuracy: 0.8625\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3626 - accuracy: 0.8505 - val_loss: 0.3539 - val_accuracy: 0.8630\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.8493 - val_loss: 0.3524 - val_accuracy: 0.8655\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8495 - val_loss: 0.3522 - val_accuracy: 0.8675\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8482 - val_loss: 0.3512 - val_accuracy: 0.8650\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.8518 - val_loss: 0.3553 - val_accuracy: 0.8660\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.8531 - val_loss: 0.3499 - val_accuracy: 0.8660\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8519 - val_loss: 0.3500 - val_accuracy: 0.8650\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8510 - val_loss: 0.3483 - val_accuracy: 0.8675\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8522 - val_loss: 0.3485 - val_accuracy: 0.8655\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8528 - val_loss: 0.3493 - val_accuracy: 0.8670\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8530 - val_loss: 0.3465 - val_accuracy: 0.8685\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3570 - accuracy: 0.8529 - val_loss: 0.3465 - val_accuracy: 0.8660\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8519 - val_loss: 0.3501 - val_accuracy: 0.8670\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8531 - val_loss: 0.3451 - val_accuracy: 0.8665\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8524 - val_loss: 0.3438 - val_accuracy: 0.8695\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3550 - accuracy: 0.8535 - val_loss: 0.3428 - val_accuracy: 0.8705\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8533 - val_loss: 0.3453 - val_accuracy: 0.8690\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8522 - val_loss: 0.3453 - val_accuracy: 0.8675\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.8539 - val_loss: 0.3431 - val_accuracy: 0.8720\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8526 - val_loss: 0.3453 - val_accuracy: 0.8685\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8525 - val_loss: 0.3438 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f45356c3048>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. Initialize & build the model (7.5 points)\n",
    "#Initialize Sequential Graph (model)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(activation = 'relu', input_dim = 10, units=6))\n",
    "model.add(tf.keras.layers.Dense(20, activation = 'relu')) \n",
    "model.add(tf.keras.layers.Dense(1,activation = 'sigmoid')) \n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train_std, Y_train, validation_data=(X_test_std,Y_test),epochs=100,batch_size=32)\n",
    "\n",
    "# This model is a good fit as it has both train & test accuracy averaging around 83% to 85%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "r9h03FEp-bJF",
    "outputId": "ab987ee9-0caf-47a2-d604-b8c04ae6b40f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                140       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 227\n",
      "Trainable params: 227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8540 - val_loss: 0.3419 - val_accuracy: 0.8705\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 0.8544 - val_loss: 0.3418 - val_accuracy: 0.8700\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8544 - val_loss: 0.3417 - val_accuracy: 0.8715\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8549 - val_loss: 0.3418 - val_accuracy: 0.8715\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8543 - val_loss: 0.3420 - val_accuracy: 0.8705\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8543 - val_loss: 0.3418 - val_accuracy: 0.8705\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8547 - val_loss: 0.3418 - val_accuracy: 0.8705\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8536 - val_loss: 0.3420 - val_accuracy: 0.8700\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8544 - val_loss: 0.3418 - val_accuracy: 0.8705\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8537 - val_loss: 0.3419 - val_accuracy: 0.8705\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8546 - val_loss: 0.3417 - val_accuracy: 0.8715\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8539 - val_loss: 0.3417 - val_accuracy: 0.8715\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8541 - val_loss: 0.3416 - val_accuracy: 0.8725\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8540 - val_loss: 0.3417 - val_accuracy: 0.8710\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8536 - val_loss: 0.3417 - val_accuracy: 0.8705\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8537 - val_loss: 0.3415 - val_accuracy: 0.8720\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8540 - val_loss: 0.3416 - val_accuracy: 0.8715\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.8544 - val_loss: 0.3416 - val_accuracy: 0.8720\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.8535 - val_loss: 0.3418 - val_accuracy: 0.8705\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.8547 - val_loss: 0.3415 - val_accuracy: 0.8715\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.8544 - val_loss: 0.3415 - val_accuracy: 0.8710\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.8539 - val_loss: 0.3418 - val_accuracy: 0.8700\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.8546 - val_loss: 0.3414 - val_accuracy: 0.8715\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.8547 - val_loss: 0.3414 - val_accuracy: 0.8710\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.8546 - val_loss: 0.3415 - val_accuracy: 0.8710\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.8539 - val_loss: 0.3413 - val_accuracy: 0.8715\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.8535 - val_loss: 0.3414 - val_accuracy: 0.8715\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.8546 - val_loss: 0.3413 - val_accuracy: 0.8715\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.8545 - val_loss: 0.3414 - val_accuracy: 0.8715\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.8541 - val_loss: 0.3413 - val_accuracy: 0.8710\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.8544 - val_loss: 0.3412 - val_accuracy: 0.8715\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8544 - val_loss: 0.3411 - val_accuracy: 0.8725\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8539 - val_loss: 0.3411 - val_accuracy: 0.8720\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8539 - val_loss: 0.3412 - val_accuracy: 0.8720\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8541 - val_loss: 0.3412 - val_accuracy: 0.8715\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8544 - val_loss: 0.3410 - val_accuracy: 0.8725\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3505 - accuracy: 0.8544 - val_loss: 0.3409 - val_accuracy: 0.8730\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8543 - val_loss: 0.3410 - val_accuracy: 0.8720\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3505 - accuracy: 0.8544 - val_loss: 0.3411 - val_accuracy: 0.8715\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3505 - accuracy: 0.8550 - val_loss: 0.3409 - val_accuracy: 0.8725\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8544 - val_loss: 0.3407 - val_accuracy: 0.8730\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3505 - accuracy: 0.8533 - val_loss: 0.3409 - val_accuracy: 0.8715\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8541 - val_loss: 0.3411 - val_accuracy: 0.8710\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8553 - val_loss: 0.3407 - val_accuracy: 0.8730\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8539 - val_loss: 0.3408 - val_accuracy: 0.8715\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8545 - val_loss: 0.3409 - val_accuracy: 0.8720\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8537 - val_loss: 0.3408 - val_accuracy: 0.8715\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8534 - val_loss: 0.3405 - val_accuracy: 0.8730\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8545 - val_loss: 0.3407 - val_accuracy: 0.8715\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8540 - val_loss: 0.3406 - val_accuracy: 0.8715\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8545 - val_loss: 0.3405 - val_accuracy: 0.8730\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8535 - val_loss: 0.3406 - val_accuracy: 0.8720\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8543 - val_loss: 0.3407 - val_accuracy: 0.8720\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8545 - val_loss: 0.3406 - val_accuracy: 0.8720\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8536 - val_loss: 0.3406 - val_accuracy: 0.8720\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8539 - val_loss: 0.3405 - val_accuracy: 0.8715\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8543 - val_loss: 0.3405 - val_accuracy: 0.8725\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8545 - val_loss: 0.3403 - val_accuracy: 0.8725\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8537 - val_loss: 0.3403 - val_accuracy: 0.8725\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8545 - val_loss: 0.3405 - val_accuracy: 0.8730\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8543 - val_loss: 0.3405 - val_accuracy: 0.8720\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8543 - val_loss: 0.3407 - val_accuracy: 0.8715\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8550 - val_loss: 0.3403 - val_accuracy: 0.8725\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8544 - val_loss: 0.3405 - val_accuracy: 0.8725\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8545 - val_loss: 0.3404 - val_accuracy: 0.8725\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8543 - val_loss: 0.3403 - val_accuracy: 0.8730\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8540 - val_loss: 0.3403 - val_accuracy: 0.8730\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8540 - val_loss: 0.3402 - val_accuracy: 0.8725\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8537 - val_loss: 0.3403 - val_accuracy: 0.8730\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8546 - val_loss: 0.3403 - val_accuracy: 0.8720\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8543 - val_loss: 0.3401 - val_accuracy: 0.8730\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8544 - val_loss: 0.3404 - val_accuracy: 0.8715\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8554 - val_loss: 0.3402 - val_accuracy: 0.8725\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8546 - val_loss: 0.3399 - val_accuracy: 0.8715\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8550 - val_loss: 0.3401 - val_accuracy: 0.8730\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8550 - val_loss: 0.3400 - val_accuracy: 0.8730\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8544 - val_loss: 0.3400 - val_accuracy: 0.8730\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.8540 - val_loss: 0.3403 - val_accuracy: 0.8720\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.8550 - val_loss: 0.3400 - val_accuracy: 0.8735\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.8544 - val_loss: 0.3402 - val_accuracy: 0.8725\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.8540 - val_loss: 0.3399 - val_accuracy: 0.8735\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8544 - val_loss: 0.3400 - val_accuracy: 0.8740\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8545 - val_loss: 0.3398 - val_accuracy: 0.8740\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8543 - val_loss: 0.3405 - val_accuracy: 0.8715\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3496 - accuracy: 0.8553 - val_loss: 0.3398 - val_accuracy: 0.8730\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3496 - accuracy: 0.8547 - val_loss: 0.3401 - val_accuracy: 0.8730\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3496 - accuracy: 0.8549 - val_loss: 0.3398 - val_accuracy: 0.8735\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8540 - val_loss: 0.3400 - val_accuracy: 0.8735\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8537 - val_loss: 0.3401 - val_accuracy: 0.8715\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8544 - val_loss: 0.3398 - val_accuracy: 0.8735\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8543 - val_loss: 0.3399 - val_accuracy: 0.8730\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8534 - val_loss: 0.3401 - val_accuracy: 0.8715\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8546 - val_loss: 0.3397 - val_accuracy: 0.8735\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8550 - val_loss: 0.3396 - val_accuracy: 0.8735\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8543 - val_loss: 0.3396 - val_accuracy: 0.8730\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8553 - val_loss: 0.3397 - val_accuracy: 0.8730\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8541 - val_loss: 0.3398 - val_accuracy: 0.8730\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8549 - val_loss: 0.3396 - val_accuracy: 0.8735\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8534 - val_loss: 0.3399 - val_accuracy: 0.8720\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8546 - val_loss: 0.3398 - val_accuracy: 0.8730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4530f41f60>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7. Optimize the model (5 points)\n",
    "from keras import optimizers\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.001)  # With learning rate \n",
    "#Compile the model\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train_std, Y_train, validation_data=(X_test_std,Y_test),epochs=100,batch_size=32)\n",
    "\n",
    "# After optimising with a reduced learning rate, train accuracy remains arouund 85% & test accuracy is around 87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o9x_D4X1_tVG",
    "outputId": "52f4fd3f-b7cf-4ac0-de2a-5664254355c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9. Predict the results using 0.5 as a threshold (5 points)\n",
    "y_pred = model.predict(X_test_std)\n",
    "y_pred = (y_pred > 0.5)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "js2zgF12_xPl",
    "outputId": "2521c292-7d5b-4e8a-9623-be40a7f9c9af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8730\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8547\n",
      "training accuracy: 0.8547499775886536\n",
      "training loss: 0.34905022382736206\n",
      "test accuracy: 0.8730000257492065\n",
      "test loss: 0.33976951241493225\n",
      "Confusion matrix:\n",
      " [[1538   55]\n",
      " [ 199  208]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.92      1593\n",
      "           1       0.79      0.51      0.62       407\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.84      0.74      0.77      2000\n",
      "weighted avg       0.87      0.87      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "test_loss, test_acc = model.evaluate(x=X_test_std,y=Y_test)\n",
    "train_loss, train_acc = model.evaluate(x=X_train_std,y=Y_train)\n",
    "print(\"training accuracy:\", train_acc)\n",
    "print(\"training loss:\", train_loss)\n",
    "print(\"test accuracy:\", test_acc)\n",
    "print(\"test loss:\", test_loss)\n",
    "\n",
    "conf_mat = metrics.confusion_matrix(y_true=Y_test, y_pred=y_pred)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSQPJXpwCYfP"
   },
   "outputs": [],
   "source": [
    "#Even though we are seeing a good train & test accuracy,by looking at confusion matrix, \n",
    "# we have to reduce the number of False positives i.e the model predicted them as customers which will not exit but they exited. \n",
    "# # it was expected to provide better results for class 0 / continuing cutomers class."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "INNDL_R6_Project-1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
