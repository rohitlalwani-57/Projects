{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of R6_ExternalLab_AIML_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YYk8NG3yOIT9"
      },
      "source": [
        "### A MNIST-like fashion product database\n",
        "\n",
        "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tFO6PuxzOIT_"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fqu1Kup7c1y5",
        "outputId": "f0f244dc-3c14-4055-e354-e5f249f99dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "efNjNImfOIUC",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l9C4aAIGOIUH",
        "outputId": "8a41668d-cd9d-4ce5-8257-b513ab01a833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HcoZBStrOIUQ"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XA1WsFSeOIUS",
        "outputId": "3645b0b4-cab0-4d4d-dccf-aaad12df0f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7jVFOyO9M6SS",
        "outputId": "ea60a229-341b-485d-e9eb-882060d9c06e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "#the dataset is inbuilt in the Keras package\n",
        "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 8us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 4s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UbiHj5YPOIUc",
        "outputId": "938037a3-623b-4837-d71c-e30bfdfe38e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(testY[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lDAYzkwyOIUj"
      },
      "source": [
        "### Convert both training and testing labels into one-hot vectors.\n",
        "\n",
        "**Hint:** check **tf.keras.utils.to_categorical()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vBlfYlANOIUk",
        "colab": {}
      },
      "source": [
        "trainY=tf.keras.utils.to_categorical(trainY,num_classes=10)\n",
        "testY=tf.keras.utils.to_categorical(testY,num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RHV3b9mzOIUq",
        "outputId": "a55db37c-a113-40d4-954b-4ab177237e30",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "print(trainY.shape)\n",
        "print('First 5 examples now are: ', trainY[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FwhQ8e7VOIUw"
      },
      "source": [
        "### Visualize the data\n",
        "\n",
        "Plot first 10 images in the triaining set and their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koAS-CyN6mp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Brby7UllJUpA",
        "outputId": "fa478294-5dc7-40fe-8d5d-efa4c3d8d91b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "label = [9,0,0,3,0,2,7,2,5,5]\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(trainX[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(label[i])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAADqCAYAAABJNfS/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCEkCv4f+mkpusOvBgAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l4TbJGeSOIU4"
      },
      "source": [
        "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ac06XZZTOIU6",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GfGk0RgTMBYO",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lSo43hjsMEvj",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(200, activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(50, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yAS26F7tMkzq",
        "colab": {}
      },
      "source": [
        "#output layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VUgdC7fWMpJv",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3hQpLv3aOIU_"
      },
      "source": [
        "### Execute the model using model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O59C_-IgOIVB",
        "outputId": "415af82f-95a5-4435-de51-108ea9673275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "source": [
        "#using 20 Epochs as it takes a lot of time to run\n",
        "model.fit(trainX,trainY,validation_data=(testX,testY),epochs=20,batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.6387 - accuracy: 0.7679 - val_loss: 0.6593 - val_accuracy: 0.7585\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.6376 - accuracy: 0.7707 - val_loss: 0.6609 - val_accuracy: 0.7618\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.6352 - accuracy: 0.7663 - val_loss: 0.6710 - val_accuracy: 0.7530\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.6284 - accuracy: 0.7637 - val_loss: 0.6456 - val_accuracy: 0.7680\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.6407 - accuracy: 0.7603 - val_loss: 0.6592 - val_accuracy: 0.7462\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.6540 - accuracy: 0.7561 - val_loss: 0.7209 - val_accuracy: 0.7328\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.6770 - accuracy: 0.7570 - val_loss: 0.6739 - val_accuracy: 0.7575\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.6479 - accuracy: 0.7674 - val_loss: 0.6624 - val_accuracy: 0.7553\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.6523 - accuracy: 0.7610 - val_loss: 0.6991 - val_accuracy: 0.7374\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.6644 - accuracy: 0.7561 - val_loss: 0.6796 - val_accuracy: 0.7332\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.6601 - accuracy: 0.7508 - val_loss: 0.6770 - val_accuracy: 0.7450\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.6568 - accuracy: 0.7547 - val_loss: 0.6927 - val_accuracy: 0.7581\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.6601 - accuracy: 0.7508 - val_loss: 0.6783 - val_accuracy: 0.7453\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.6746 - accuracy: 0.7475 - val_loss: 0.7066 - val_accuracy: 0.7421\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.6680 - accuracy: 0.7526 - val_loss: 0.7081 - val_accuracy: 0.7399\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.6637 - accuracy: 0.7498 - val_loss: 0.6927 - val_accuracy: 0.7306\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.6632 - accuracy: 0.7526 - val_loss: 0.6873 - val_accuracy: 0.7212\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.6860 - accuracy: 0.7372 - val_loss: 0.7000 - val_accuracy: 0.7316\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.6709 - accuracy: 0.7492 - val_loss: 0.6999 - val_accuracy: 0.7555\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.6686 - accuracy: 0.7527 - val_loss: 0.7180 - val_accuracy: 0.7285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2e3b1ce630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tf3DAJTZPkVZ",
        "outputId": "7212fbb3-08f8-4e02-a34e-fa577b675c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 182,660\n",
            "Trainable params: 182,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JdzDtGwDOIVF"
      },
      "source": [
        "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kndfpdidOIVI",
        "colab": {}
      },
      "source": [
        "model1 = tf.keras.models.Sequential()\n",
        "model1.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "model1.add(tf.keras.layers.BatchNormalization())\n",
        "model1.add(tf.keras.layers.Dense(200, activation='sigmoid'))\n",
        "model1.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
        "model1.add(tf.keras.layers.Dense(50, activation='sigmoid'))\n",
        "model1.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model1.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mwk3T5LJOIVN"
      },
      "source": [
        "### Execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JNLR8tcBOIVP",
        "outputId": "2201140e-52d7-4d3c-adc4-213ea2ecb181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "source": [
        "model1.fit(trainX,trainY,validation_data=(testX,testY),epochs=20,batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 9s 147us/sample - loss: 2.1498 - accuracy: 0.3948 - val_loss: 1.8675 - val_accuracy: 0.5720\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 1.4995 - accuracy: 0.5712 - val_loss: 1.2134 - val_accuracy: 0.6390\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 1.0833 - accuracy: 0.6680 - val_loss: 0.9472 - val_accuracy: 0.7194\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.8760 - accuracy: 0.7186 - val_loss: 0.7857 - val_accuracy: 0.7405\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.7539 - accuracy: 0.7378 - val_loss: 0.6976 - val_accuracy: 0.7527\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.6842 - accuracy: 0.7552 - val_loss: 0.6432 - val_accuracy: 0.7634\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.6384 - accuracy: 0.7668 - val_loss: 0.6054 - val_accuracy: 0.7792\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.6031 - accuracy: 0.7798 - val_loss: 0.5755 - val_accuracy: 0.7903\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.5759 - accuracy: 0.7910 - val_loss: 0.5512 - val_accuracy: 0.8010\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.5526 - accuracy: 0.8008 - val_loss: 0.5326 - val_accuracy: 0.8101\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 9s 144us/sample - loss: 0.5336 - accuracy: 0.8074 - val_loss: 0.5159 - val_accuracy: 0.8136\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 9s 146us/sample - loss: 0.5165 - accuracy: 0.8155 - val_loss: 0.5032 - val_accuracy: 0.8208\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.5035 - accuracy: 0.8218 - val_loss: 0.4917 - val_accuracy: 0.8226\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 9s 143us/sample - loss: 0.4884 - accuracy: 0.8264 - val_loss: 0.4818 - val_accuracy: 0.8271\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 9s 145us/sample - loss: 0.4792 - accuracy: 0.8292 - val_loss: 0.4724 - val_accuracy: 0.8314\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.4689 - accuracy: 0.8338 - val_loss: 0.4644 - val_accuracy: 0.8338\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.4590 - accuracy: 0.8362 - val_loss: 0.4584 - val_accuracy: 0.8353\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.4506 - accuracy: 0.8388 - val_loss: 0.4501 - val_accuracy: 0.8377\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.4430 - accuracy: 0.8430 - val_loss: 0.4442 - val_accuracy: 0.8404\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.4335 - accuracy: 0.8454 - val_loss: 0.4382 - val_accuracy: 0.8427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2e49c5ea58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u7kRSPxyQBCn",
        "outputId": "f124aa05-cbea-4f9c-91dd-f467e5839a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_1 (Reshape)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 185,796\n",
            "Trainable params: 184,228\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Py-KwkmjOIVU"
      },
      "source": [
        "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yLXUE9jWOIVV",
        "outputId": "b2f5bc98-5961-4f75-a9ae-893fba739183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model2 = tf.keras.models.Sequential()\n",
        "model2.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "model2.add(tf.keras.layers.Dense(200, activation='sigmoid'))\n",
        "model2.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
        "model2.add(tf.keras.layers.Dense(50, activation='sigmoid'))\n",
        "model2.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "tf.keras.optimizers.SGD(learning_rate=0.001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD at 0x7f2e49b1c9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pJUqA5T4OIVc",
        "colab": {}
      },
      "source": [
        "model2.compile(loss='categorical_crossentropy', optimizer='sgd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KyOLanT2QJM_",
        "outputId": "7db8d6b0-183d-46df-a78f-372535e1ae1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "source": [
        "model2.fit(trainX,trainY,validation_data=(testX,testY),epochs=20,batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 9s 146us/sample - loss: 2.1302 - val_loss: 1.8282\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 1.5185 - val_loss: 1.2634\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 1.1259 - val_loss: 0.9782\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.9005 - val_loss: 0.8050\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.7672 - val_loss: 0.7093\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.6935 - val_loss: 0.6535\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.6457 - val_loss: 0.6146\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.6095 - val_loss: 0.5828\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.5814 - val_loss: 0.5564\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.5567 - val_loss: 0.5361\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 0.5358 - val_loss: 0.5176\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.5164 - val_loss: 0.5029\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.5029 - val_loss: 0.4900\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.4861 - val_loss: 0.4788\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.4777 - val_loss: 0.4698\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.4657 - val_loss: 0.4611\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.4567 - val_loss: 0.4544\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.4484 - val_loss: 0.4462\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 9s 142us/sample - loss: 0.4395 - val_loss: 0.4414\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.4313 - val_loss: 0.4357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2e49a06518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bra-D0CKQNiL",
        "colab": {}
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j9CSqKvpOIVk"
      },
      "source": [
        "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GGAad54JOIVm",
        "outputId": "7f89a35d-bb6c-4a34-f98c-3271391365bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model3 = tf.keras.models.Sequential()\n",
        "model3.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "model3.add(tf.keras.layers.BatchNormalization())\n",
        "model3.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
        "model3.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
        "model3.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "tf.keras.optimizers.SGD(learning_rate=0.03)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD at 0x7f2e3eac3b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MQ7oIymROIVp",
        "colab": {}
      },
      "source": [
        "model3.compile(loss='categorical_crossentropy', optimizer='sgd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nr2YsZV0OIV0"
      },
      "source": [
        "## Review model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h4ojW6-oOIV2",
        "outputId": "25054029-9e47-4203-b2fe-cb878e49dd41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_4 (Reshape)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 92,746\n",
            "Trainable params: 91,178\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gfFGmbZLOIV5"
      },
      "source": [
        "### Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bIkbMEN5OIV7",
        "outputId": "81b38ab3-8324-41d2-ecb1-1d4c3ef1c4db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "source": [
        "model1.fit(trainX,trainY,validation_data=(testX,testY),epochs=20,batch_size=32) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 9s 143us/sample - loss: 0.4275 - accuracy: 0.8476 - val_loss: 0.4330 - val_accuracy: 0.8429\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.4219 - accuracy: 0.8495 - val_loss: 0.4292 - val_accuracy: 0.8469\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.4140 - accuracy: 0.8522 - val_loss: 0.4229 - val_accuracy: 0.8465\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.4102 - accuracy: 0.8529 - val_loss: 0.4198 - val_accuracy: 0.8487\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.4030 - accuracy: 0.8563 - val_loss: 0.4166 - val_accuracy: 0.8497\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.3992 - accuracy: 0.8591 - val_loss: 0.4087 - val_accuracy: 0.8514\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.3925 - accuracy: 0.8598 - val_loss: 0.4061 - val_accuracy: 0.8508\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.3857 - accuracy: 0.8640 - val_loss: 0.4009 - val_accuracy: 0.8536\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.3821 - accuracy: 0.8640 - val_loss: 0.3976 - val_accuracy: 0.8530\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.3777 - accuracy: 0.8647 - val_loss: 0.3952 - val_accuracy: 0.8541\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.3731 - accuracy: 0.8674 - val_loss: 0.3903 - val_accuracy: 0.8571\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.3686 - accuracy: 0.8687 - val_loss: 0.3874 - val_accuracy: 0.8594\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.3654 - accuracy: 0.8690 - val_loss: 0.3859 - val_accuracy: 0.8583\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.3592 - accuracy: 0.8705 - val_loss: 0.3818 - val_accuracy: 0.8593\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 9s 143us/sample - loss: 0.3573 - accuracy: 0.8716 - val_loss: 0.3795 - val_accuracy: 0.8604\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.3524 - accuracy: 0.8733 - val_loss: 0.3749 - val_accuracy: 0.8601\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.3476 - accuracy: 0.8759 - val_loss: 0.3721 - val_accuracy: 0.8623\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.3447 - accuracy: 0.8747 - val_loss: 0.3691 - val_accuracy: 0.8648\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.3391 - accuracy: 0.8792 - val_loss: 0.3679 - val_accuracy: 0.8661\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.3352 - accuracy: 0.8796 - val_loss: 0.3664 - val_accuracy: 0.8641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2e3ea15f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}